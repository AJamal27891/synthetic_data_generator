{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthetic Data Validation Notebook\n",
    "\n",
    "This notebook validates the synthetic TPC-DSâ€“like dataset generated by our project. It performs the following checks:\n",
    "\n",
    "1. Loads all CSV files from the `data/` directory.\n",
    "2. Verifies primary key uniqueness for dimension and fact tables.\n",
    "3. Checks foreign key relationships between tables.\n",
    "4. Verifies that the aggregated order totals from transactions match the `order_total` in the orders table.\n",
    "5. Loads and displays metadata from the JSON schema file.\n",
    "6. Reports any inconsistencies found.\n",
    "\n",
    "**Note:** Adjust file paths if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "\n",
    "Define file paths\n",
    "data_dir = \"../data/\"\n",
    "metadata_dir = \"../metadata/\"\n",
    "\n",
    "customers_file = data_dir + \"customers.csv\"\n",
    "products_file = data_dir + \"products.csv\"\n",
    "stores_file = data_dir + \"stores.csv\"\n",
    "promotions_file = data_dir + \"promotions.csv\"\n",
    "dates_file = data_dir + \"dates.csv\"\n",
    "orders_file = data_dir + \"orders.csv\"\n",
    "transactions_file = data_dir + \"transactions.csv\"\n",
    "inventory_file = data_dir + \"inventory.csv\"\n",
    "returns_file = data_dir + \"returns.csv\"\n",
    "\n",
    "schema_metadata_file = metadata_dir + \"schema_metadata.json\"\n",
    "etl_lineage_file = metadata_dir + \"generation_lineage.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames loaded successfully!\n",
      "Customers: 10000 rows\n",
      "Products: 1000 rows\n",
      "Stores: 100 rows\n",
      "Promotions: 100 rows\n",
      "Dates: 365 rows\n",
      "Orders: 10000 rows\n",
      "Transactions: 30023 rows\n",
      "Inventory: 10000 rows\n",
      "Returns: 1000 rows\n"
     ]
    }
   ],
   "source": [
    "customers = pd.read_csv(customers_file)\n",
    "products = pd.read_csv(products_file)\n",
    "stores = pd.read_csv(stores_file)\n",
    "promotions = pd.read_csv(promotions_file)\n",
    "dates = pd.read_csv(dates_file)\n",
    "orders = pd.read_csv(orders_file, parse_dates=[\"order_date\"])\n",
    "transactions = pd.read_csv(transactions_file)\n",
    "inventory = pd.read_csv(inventory_file)\n",
    "returns = pd.read_csv(returns_file)\n",
    "\n",
    "print(\"DataFrames loaded successfully!\")\n",
    "print(f\"Customers: {customers.shape[0]} rows\")\n",
    "print(f\"Products: {products.shape[0]} rows\")\n",
    "print(f\"Stores: {stores.shape[0]} rows\")\n",
    "print(f\"Promotions: {promotions.shape[0]} rows\")\n",
    "print(f\"Dates: {dates.shape[0]} rows\")\n",
    "print(f\"Orders: {orders.shape[0]} rows\")\n",
    "print(f\"Transactions: {transactions.shape[0]} rows\")\n",
    "print(f\"Inventory: {inventory.shape[0]} rows\")\n",
    "print(f\"Returns: {returns.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Primary Key Uniqueness Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primary Key Checks:\n",
      "PASS: Customers - All 10000 rows have unique 'customer_id'.\n",
      "PASS: Products - All 1000 rows have unique 'product_id'.\n",
      "PASS: Stores - All 100 rows have unique 'store_id'.\n",
      "PASS: Promotions - All 100 rows have unique 'promo_id'.\n",
      "PASS: Dates - All 365 rows have unique 'date_id'.\n",
      "PASS: Orders - All 10000 rows have unique 'order_id'.\n",
      "PASS: Transactions - All 30023 rows have unique 'transaction_id'.\n",
      "PASS: Returns - All 1000 rows have unique 'return_id'.\n"
     ]
    }
   ],
   "source": [
    "def check_uniqueness(df, key, table_name):\n",
    "    unique_count = df[key].nunique()\n",
    "    total_count = df.shape[0]\n",
    "    if unique_count == total_count:\n",
    "        print(f\"PASS: {table_name} - All {total_count} rows have unique '{key}'.\")\n",
    "    else:\n",
    "        print(f\"FAIL: {table_name} - Only {unique_count} unique '{key}' found out of {total_count} rows.\")\n",
    "\n",
    "print(\"\\nPrimary Key Checks:\")\n",
    "check_uniqueness(customers, 'customer_id', 'Customers')\n",
    "check_uniqueness(products, 'product_id', 'Products')\n",
    "check_uniqueness(stores, 'store_id', 'Stores')\n",
    "check_uniqueness(promotions, 'promo_id', 'Promotions')\n",
    "check_uniqueness(dates, 'date_id', 'Dates')\n",
    "check_uniqueness(orders, 'order_id', 'Orders')\n",
    "check_uniqueness(transactions, 'transaction_id', 'Transactions')\n",
    "Returns table should also have unique return_id if exists\n",
    "if 'return_id' in returns.columns:\n",
    "    check_uniqueness(returns, 'return_id', 'Returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foreign Key Consistency Checks\n",
    "\n",
    "We verify that:\n",
    "- Every `customer_id` in Orders exists in Customers.\n",
    "- Every `store_id` in Orders exists in Stores.\n",
    "- Every `order_id` in Transactions exists in Orders.\n",
    "- Every `product_id` in Transactions exists in Products.\n",
    "- If `promo_id` is provided in Transactions, it exists in Promotions.\n",
    "- Similarly, check for Inventory and Returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Foreign Key Checks:\n",
      "PASS: All values in Orders.customer_id exist in Customers.customer_id.\n",
      "PASS: All values in Orders.store_id exist in Stores.store_id.\n",
      "PASS: All values in Transactions.order_id exist in Orders.order_id.\n",
      "PASS: All values in Transactions.product_id exist in Products.product_id.\n",
      "PASS: All values in Transactions.promo_id exist in Promotions.promo_id.\n",
      "PASS: All values in Inventory.store_id exist in Stores.store_id.\n",
      "PASS: All values in Inventory.product_id exist in Products.product_id.\n",
      "PASS: All values in Returns.order_id exist in Orders.order_id.\n",
      "PASS: All values in Returns.product_id exist in Products.product_id.\n"
     ]
    }
   ],
   "source": [
    "def check_foreign_key(child_df, child_key, parent_df, parent_key, child_table, parent_table):\n",
    "    missing = child_df[~child_df[child_key].isin(parent_df[parent_key])]\n",
    "    if missing.empty:\n",
    "        print(f\"PASS: All values in {child_table}.{child_key} exist in {parent_table}.{parent_key}.\")\n",
    "    else:\n",
    "        print(f\"FAIL: {child_table}.{child_key} has {missing.shape[0]} values not found in {parent_table}.{parent_key}.\")\n",
    "\n",
    "print(\"\\nForeign Key Checks:\")\n",
    "check_foreign_key(orders, 'customer_id', customers, 'customer_id', 'Orders', 'Customers')\n",
    "check_foreign_key(orders, 'store_id', stores, 'store_id', 'Orders', 'Stores')\n",
    "check_foreign_key(transactions, 'order_id', orders, 'order_id', 'Transactions', 'Orders')\n",
    "check_foreign_key(transactions, 'product_id', products, 'product_id', 'Transactions', 'Products')\n",
    "# For promo_id, drop nulls before checking\n",
    "if 'promo_id' in transactions.columns:\n",
    "    check_foreign_key(transactions.dropna(subset=['promo_id']), 'promo_id', promotions, 'promo_id', 'Transactions', 'Promotions')\n",
    "check_foreign_key(inventory, 'store_id', stores, 'store_id', 'Inventory', 'Stores')\n",
    "check_foreign_key(inventory, 'product_id', products, 'product_id', 'Inventory', 'Products')\n",
    "check_foreign_key(returns, 'order_id', orders, 'order_id', 'Returns', 'Orders')\n",
    "check_foreign_key(returns, 'product_id', products, 'product_id', 'Returns', 'Products')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthetic_data_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
